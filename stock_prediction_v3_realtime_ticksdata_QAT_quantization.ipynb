{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4CATJiF_A1VI"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch.utils.data import DataLoader, TensorDataset, Subset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, ParameterGrid\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "import random\n",
    "import json\n",
    "import seaborn as sns\n",
    "import time\n",
    "import itertools\n",
    "import cProfile\n",
    "from torch.utils.checkpoint import checkpoint\n",
    "import torch.nn.functional as F\n",
    "from scipy.stats import entropy\n",
    "from scipy.interpolate import interp1d\n",
    "from TimeSeriesDataset import TimeSeriesDataset\n",
    "import logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XXcNnnW_C3XC"
   },
   "source": [
    "## Data Preparation & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UOXSnPeqEO7q"
   },
   "outputs": [],
   "source": [
    "def load_configs(filename):\n",
    "    with open(f'configs/{filename}.json', 'r') as file:\n",
    "        return json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nxRE-Z-hBRWh"
   },
   "outputs": [],
   "source": [
    "# Plot functions\n",
    "def plot_last_prices(last_prices, normalized=True):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(last_prices, label='Normalized Prices')\n",
    "    plt.legend()\n",
    "    plt.ylabel('Normalized Price' if normalized else 'Price')\n",
    "    plt.xlabel('Time Index')\n",
    "    plt.title('Relative Change Rates of Close Prices' if normalized else 'Close Prices')\n",
    "    plt.show()\n",
    "\n",
    "def plot_volume(data, title):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(data['datetime'], data['volume'])\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Trade Volume')\n",
    "    plt.title(title)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()\n",
    "\n",
    "def plot_prices_with_ma(data, period, period_labels):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(data.index, data['last_price'], label='Last Price')\n",
    "    for i in range(len(period)):\n",
    "      t = period[i]\n",
    "      period_label = period_labels[i]\n",
    "      plt.plot(data.index, data[f'ma({t})'], label=f'{period_label} MA')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Last Price')\n",
    "    plt.title('Prices with Moving Average')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def plot_prices_with_macd(data, short_period, long_period, signal_period):\n",
    "    for i in range(len(short_period)):\n",
    "      plt.figure(figsize=(10, 5))\n",
    "      a = short_period[i]\n",
    "      b = long_period[i]\n",
    "      c = signal_period[i]\n",
    "      plt.plot(data.index, data[f'macd_line({a},{b},{c})'], label=f'MACD')\n",
    "      plt.plot(data.index, data[f'signal_line({a},{b},{c})'], label=f'Signal')\n",
    "      plt.plot(data.index, data[f'macd_histogram({a},{b},{c})'], label=f'Histogram')\n",
    "      plt.xlabel('Date')\n",
    "      plt.ylabel('Convergence/Divergence')\n",
    "      plt.title(f\"MACD({a},{b},{c})\")\n",
    "      plt.legend()\n",
    "      plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XkiCBffzERr9"
   },
   "outputs": [],
   "source": [
    "# Moving Average (MA)\n",
    "def moving_average(last_prices, num_periods):\n",
    "    ma = last_prices.rolling(window=num_periods, min_periods=1).mean()\n",
    "    # Forward fill the first num_periods-1 NaN values with the first non-NaN value\n",
    "    ma.ffill(inplace=True)\n",
    "    return ma\n",
    "\n",
    "def calculate_ema(data, period):\n",
    "    alpha = 2 / (period + 1)\n",
    "    ema = [data.iloc[0]]  # EMA starts with the first data point\n",
    "\n",
    "    for price in data.iloc[1:]:\n",
    "        ema.append(alpha * price + (1 - alpha) * ema[-1])\n",
    "\n",
    "    return pd.Series(ema, index=data.index)\n",
    "\n",
    "# Moving Average Convergence/Divergence (MACD)\n",
    "def calculate_macd(data, short_period, long_period, signal_period):\n",
    "    short_ema = calculate_ema(data, short_period)\n",
    "    long_ema = calculate_ema(data, long_period)\n",
    "\n",
    "    macd_line = short_ema - long_ema\n",
    "    signal_line = calculate_ema(macd_line, signal_period)\n",
    "    macd_histogram = macd_line - signal_line\n",
    "\n",
    "    return macd_line, signal_line, macd_histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kq3mxEWoEUt-"
   },
   "outputs": [],
   "source": [
    "def filter_data_by_intervals(data, intervals):\n",
    "    # Initialize a mask with False values\n",
    "    interval_mask = pd.Series([False] * len(data))\n",
    "\n",
    "    # Iterate over intervals and apply masks\n",
    "    for start, end in intervals:\n",
    "        start_time = pd.to_datetime(start).time()\n",
    "        end_time = pd.to_datetime(end).time()\n",
    "\n",
    "        # Create masks for start and end times\n",
    "        start_time_mask = (data['datetime'].dt.time >= start_time)\n",
    "        end_time_mask = (data['datetime'].dt.time <= end_time)\n",
    "\n",
    "        # Combine masks based on interval crossing midnight or not\n",
    "        if start_time <= end_time:\n",
    "            interval_mask |= (start_time_mask & end_time_mask)\n",
    "        else:\n",
    "            interval_mask |= (start_time_mask | end_time_mask)\n",
    "\n",
    "    # Apply the final mask to filter the data\n",
    "    data_filtered = data[interval_mask]\n",
    "    return data_filtered\n",
    "\n",
    "def assert_time_intervals(df, intervals):\n",
    "    df.index = pd.to_datetime(df.index)\n",
    "    times = df.index.time\n",
    "\n",
    "    time_intervals = [(pd.Timestamp(start).time(), pd.Timestamp(end).time()) for start, end in intervals]\n",
    "\n",
    "    def is_within_intervals(t):\n",
    "        return any(start <= t <= end if start <= end else start <= t or t <= end for start, end in time_intervals)\n",
    "\n",
    "    outside_intervals = ~np.vectorize(is_within_intervals)(times)\n",
    "\n",
    "    if outside_intervals.any():\n",
    "        print(\"There are times outside the specified intervals:\")\n",
    "        print(df[outside_intervals])\n",
    "    else:\n",
    "        print(\"All times are within the specified intervals.\")\n",
    "\n",
    "    assert(not outside_intervals.any())\n",
    "\n",
    "def set_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "def extract_main_contract(data_filtered, window=1000, min_periods=1, quantile=0.80):\n",
    "    # Compute the rolling mean of volume\n",
    "    data_filtered.loc[:, 'volume_rolling'] = data_filtered['volume'].rolling(window=window, min_periods=min_periods).mean()\n",
    "\n",
    "    # Calculate the volume threshold based on the quantile\n",
    "    volume_threshold = data_filtered['volume_rolling'].quantile(quantile)\n",
    "\n",
    "    # Identify high volume segments\n",
    "    data_filtered.loc[:, 'high_volume'] = data_filtered['volume_rolling'] > volume_threshold\n",
    "\n",
    "    # Segment identification by cumulative sum of changes in high_volume status\n",
    "    data_filtered.loc[:, 'segment'] = data_filtered['high_volume'].ne(data_filtered['high_volume'].shift()).cumsum()\n",
    "\n",
    "    # Filter the high volume segments and fill NaN values\n",
    "    high_volume_segments = data_filtered[data_filtered['high_volume']]\n",
    "    high_volume_segments.loc[:, 'volume'] = high_volume_segments['volume'].ffill()\n",
    "\n",
    "    # Drop the temporary columns\n",
    "    high_volume_segments.drop(columns=['high_volume', 'segment', 'volume_rolling'], inplace=True)\n",
    "\n",
    "    return high_volume_segments\n",
    "\n",
    "\n",
    "def normalize_prices(data_array, intervals, timestamps, num_steps, input_size, last_price_index=0):\n",
    "    # Convert timestamps to time objects\n",
    "    timestamp_times = timestamps.time\n",
    "\n",
    "    # Create an empty array to collect normalized prices\n",
    "    normalized_last_price = np.full(len(data_array), np.nan)  # Use NaN to identify unassigned values\n",
    "\n",
    "    for start, end in intervals:\n",
    "        start_time = pd.Timestamp(start).time()\n",
    "        end_time = pd.Timestamp(end).time()\n",
    "\n",
    "        # Create masks for the interval\n",
    "        start_mask = timestamp_times >= start_time\n",
    "        end_mask = timestamp_times <= end_time\n",
    "        if start_time <= end_time:\n",
    "            interval_mask = start_mask & end_mask\n",
    "        else:\n",
    "            interval_mask = start_mask | end_mask\n",
    "\n",
    "        # Filter data by interval\n",
    "        interval_data = data_array[interval_mask]\n",
    "        clear_gpu_cache()\n",
    "        if len(interval_data) == 0:\n",
    "            continue\n",
    "\n",
    "        num_windows = (len(interval_data) + input_size - 1) // input_size\n",
    "        windows = np.array_split(interval_data, num_windows)\n",
    "\n",
    "        # Create array to hold normalized values for the current interval\n",
    "        interval_normalized_last_price = np.full(len(interval_data), np.nan)\n",
    "\n",
    "        start_idx = 0\n",
    "        for window_data in windows:\n",
    "            if len(window_data) == 0:\n",
    "                continue\n",
    "\n",
    "            if start_idx == 0:\n",
    "                window_first_price = window_data[0, last_price_index]\n",
    "                values = window_data[:, last_price_index] / window_first_price - 1.0\n",
    "            else:\n",
    "                window_last_price = window_data[-1, last_price_index]\n",
    "                values = window_data[:, last_price_index] / window_last_price - 1.0\n",
    "\n",
    "            end_idx = start_idx + len(window_data)\n",
    "            interval_normalized_last_price[start_idx:end_idx] = values\n",
    "            start_idx = end_idx\n",
    "\n",
    "        normalized_last_price[interval_mask] = interval_normalized_last_price\n",
    "\n",
    "    # Set to the data array\n",
    "    data_array[:, last_price_index] = normalized_last_price\n",
    "\n",
    "    # Process all outliers - impute with its previous non-outlying value\n",
    "    postprocess_outliers(data_array)\n",
    "\n",
    "    # Check for NaN values\n",
    "    if np.isnan(data_array[:, last_price_index]).any():\n",
    "        raise ValueError(\"Data contains NaN values after normalization. Please check the normalization process.\")\n",
    "\n",
    "    return data_array\n",
    "\n",
    "\n",
    "def postprocess_outliers(data, threshold=0.5):\n",
    "    outlier_indices = np.where(np.abs(data[:, 0]) > threshold)[0]\n",
    "\n",
    "    for idx in outlier_indices:\n",
    "        previous_value_idx = idx - 1\n",
    "        while data[previous_value_idx, 0] > threshold and previous_value_idx > 0:\n",
    "            previous_value_idx -= 1\n",
    "        data[idx, 0] = data[previous_value_idx, 0]\n",
    "\n",
    "def roll_data(data_array, num_steps, input_size):\n",
    "    # Roll data to reshape it into the 4D shape (N, num_steps, input_size, # features)\n",
    "    data_array = [np.array(data_array[i * input_size: (i + 1) * input_size])\n",
    "                  for i in range(len(data_array) // input_size)]\n",
    "    data_array = np.stack(data_array)\n",
    "    return data_array\n",
    "\n",
    "\n",
    "# Generator function\n",
    "def data_generator(data_array, indices, num_steps, batch_size, last_price_index=0):\n",
    "    total_len = len(indices)\n",
    "    for start_idx in range(0, total_len, batch_size):\n",
    "        end_idx = min(start_idx + batch_size, total_len)\n",
    "        batch_indices = indices[start_idx:end_idx]\n",
    "        X_batch = np.array([data_array[i: i + num_steps] for i in batch_indices])\n",
    "        y_batch = data_array[batch_indices + num_steps, :, last_price_index]\n",
    "        yield X_batch, y_batch\n",
    "\n",
    "\n",
    "# Train-test split function\n",
    "def train_test_split(data_array, num_steps, input_size, val_split, test_split, last_price_index=0):\n",
    "    # Calculate the total number of samples\n",
    "    total_len = len(data_array) - num_steps\n",
    "\n",
    "    X = np.empty((total_len, num_steps, input_size, data_array.shape[-1] - 1), dtype=np.float32)\n",
    "    y = np.empty((total_len, num_steps), dtype=np.float32)\n",
    "\n",
    "    for i in range(total_len):\n",
    "        X[i] = data_array[i:i + num_steps, :, 1:]  # Exclude the last_price column (column 0)\n",
    "        y[i] = data_array[i:i + num_steps, :, last_price_index]  # Store the last_price values\n",
    "\n",
    "    # Check the shapes of X and y\n",
    "    num_features = data_array.shape[-1] - 1  # Exclude the last_price column\n",
    "    assert X.shape == (total_len, num_steps, input_size, num_features), f\"X shape mismatch: {X.shape}\"\n",
    "    assert y.shape == (total_len, num_steps), f\"y shape mismatch: {y.shape}\"\n",
    "    assert len(X) == len(y), \"Number of samples in X and y must be equal\"\n",
    "\n",
    "    # Determine the split indices\n",
    "    test_start = int(total_len * (1 - test_split))\n",
    "    val_start = int(total_len * (1 - test_split - val_split))\n",
    "\n",
    "    # Split the data\n",
    "    X_train, X_val, X_test = X[:val_start], X[val_start:test_start], X[test_start:]\n",
    "    y_train, y_val, y_test = y[:val_start], y[val_start:test_start], y[test_start:]\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test\n",
    "\n",
    "def normalize_data(data):\n",
    "    scaler = MinMaxScaler()\n",
    "    normalized_data = scaler.fit_transform(data)\n",
    "    normalized_df = pd.DataFrame(normalized_data, index=data.index, columns=data.columns)\n",
    "    return normalized_df\n",
    "\n",
    "# Create dataloader instances\n",
    "def create_dataloader_instances(dataset, val_split, test_split, batch_size, num_workers=8):\n",
    "    dataset_size = len(dataset)\n",
    "    test_size = int(test_split * dataset_size)\n",
    "    val_size = int(val_split * (dataset_size - test_size))\n",
    "    train_size = dataset_size - val_size - test_size\n",
    "\n",
    "    train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
    "\n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "# Create forward fill bid custom\n",
    "def forward_fill_bid_custom(data, price_cols):\n",
    "    # Forward fill NaN values across rows for specified columns\n",
    "    data[price_cols] = data[price_cols].ffill(axis=1)\n",
    "\n",
    "    # Forward fill NaN values across columns for specified columns\n",
    "    data[price_cols] = data[price_cols].ffill(axis=0)\n",
    "\n",
    "    return data\n",
    "\n",
    "def clear_gpu_cache():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "# Create sequences based on the extended_segment\n",
    "def create_sequences(extended_segment, num_steps, input_size, normalize, val_split=0.1, test_split=0.1, batch_size=64):\n",
    "    # Ensure no NaN values\n",
    "    assert(np.isnan(extended_segment).sum().sum() == 0)\n",
    "\n",
    "    # Setup\n",
    "    timestamps = extended_segment.index\n",
    "    extended_segment = extended_segment.to_numpy()\n",
    "    last_price_index = 0\n",
    "\n",
    "    # Prevent a division by 0 by imputing 0s to a very small number\n",
    "    extended_segment[:, last_price_index] = np.where(extended_segment[:, last_price_index] == 0, 1e-6, extended_segment[:, last_price_index])\n",
    "\n",
    "    # Plot the prices before normalization\n",
    "    plot_last_prices(extended_segment[:, last_price_index], normalized=False)\n",
    "\n",
    "    # Normalize prices - retrieve relative change rates\n",
    "    if normalize:\n",
    "        extended_segment = normalize_prices(extended_segment, intervals, timestamps, num_steps, input_size, last_price_index)\n",
    "\n",
    "    clear_gpu_cache()\n",
    "\n",
    "    # Plot the prices after normalization\n",
    "    plot_last_prices(extended_segment[:, last_price_index])\n",
    "\n",
    "    # Roll data for RNN\n",
    "    extended_segment = roll_data(extended_segment, num_steps, input_size)\n",
    "    clear_gpu_cache()\n",
    "\n",
    "    # Create dataset and dataloader instances\n",
    "    dataset = TimeSeriesDataset(extended_segment, num_steps, last_price_index)\n",
    "    clear_gpu_cache()\n",
    "    train_loader, val_loader, test_loader = create_dataloader_instances(dataset, val_split=val_split, test_split=test_split, batch_size=batch_size)\n",
    "    clear_gpu_cache()\n",
    "    \n",
    "    # # Remove all rows with exceptionally small bid ask spread\n",
    "    # extended_segment = extended_segment[:, ]\n",
    "\n",
    "    return extended_segment, train_loader, val_loader, test_loader, dataset.num_features\n",
    "\n",
    "\n",
    "def add_derived_features(extended_segment):\n",
    "    # Forward fill nan values in bid_prices (NOTE: This may not reflect the changes in market!)\n",
    "    bid_price_cols = ['bid_price1', 'bid_price2', 'bid_price3', 'bid_price4', 'bid_price5']\n",
    "    ask_price_cols = ['ask_price1', 'ask_price2', 'ask_price3', 'ask_price4', 'ask_price5']\n",
    "    extended_segment = forward_fill_bid_custom(extended_segment, bid_price_cols)\n",
    "\n",
    "    # Bid & Ask Volumes\n",
    "    bid_volume_cols = ['bid_volume1', 'bid_volume2', 'bid_volume3', 'bid_volume4', 'bid_volume5']\n",
    "    ask_volume_cols = ['ask_volume1', 'ask_volume2', 'ask_volume3', 'ask_volume4', 'ask_volume5']\n",
    "\n",
    "    # Calculate Bid-Ask Spread\n",
    "    extended_segment.loc[:, 'bid_ask_spread'] = extended_segment['ask_price1'] - extended_segment['bid_price1']\n",
    "\n",
    "    # Calculate Market Depth (total bid and ask volumes)\n",
    "    extended_segment.loc[:, 'total_bid_volume'] = extended_segment[bid_volume_cols].sum(axis=1)\n",
    "    extended_segment.loc[:, 'total_ask_volume'] = extended_segment[ask_volume_cols].sum(axis=1)\n",
    "\n",
    "    # Calculate Order Imbalance Ratio\n",
    "    extended_segment.loc[:, 'order_imbalance_ratio'] = (extended_segment['total_bid_volume'] - extended_segment['total_ask_volume']) / (extended_segment['total_bid_volume'] + extended_segment['total_ask_volume'])\n",
    "\n",
    "    # Calculate Volume Order Imbalance\n",
    "    delta_bid_vol = extended_segment[bid_volume_cols].diff().fillna(0)\n",
    "    delta_ask_vol = extended_segment[ask_volume_cols].diff().fillna(0)\n",
    "    delta_bid_price = extended_segment[bid_price_cols].diff().fillna(0)\n",
    "    delta_ask_price = extended_segment[ask_price_cols].diff().fillna(0)\n",
    "\n",
    "    for i in range(1, 6):\n",
    "        bid_vol_col = f'bid_volume{i}'\n",
    "        ask_vol_col = f'ask_volume{i}'\n",
    "        bid_price_col = f'bid_price{i}'\n",
    "        ask_price_col = f'ask_price{i}'\n",
    "\n",
    "        # Clip delta_bid_vol to bid_volume on a rise\n",
    "        delta_bid_vol[bid_vol_col] = np.where(delta_bid_price[bid_price_col] > 0,\n",
    "                                              np.minimum(delta_bid_vol[bid_vol_col], extended_segment[bid_vol_col]),\n",
    "                                              delta_bid_vol[bid_vol_col])\n",
    "\n",
    "        # Clip delta_ask_vol to ask_volume on a fall\n",
    "        delta_ask_vol[ask_vol_col] = np.where(delta_ask_price[ask_price_col] < 0,\n",
    "                                              np.minimum(delta_ask_vol[ask_vol_col], extended_segment[ask_vol_col]),\n",
    "                                              delta_ask_vol[ask_vol_col])\n",
    "\n",
    "    extended_segment.loc[:, 'volume_order_imbalance'] = delta_bid_vol.sum(axis=1) - delta_ask_vol.sum(axis=1)\n",
    "\n",
    "    # Calculate Mid-Price Basis\n",
    "    extended_segment.loc[:, 'mid_price'] = (extended_segment.loc[:, 'bid_price1'] + extended_segment.loc[:, 'ask_price1']) / 2\n",
    "\n",
    "    # Calculate average trade price if it doesn't exist\n",
    "    if 'average_trade_price' not in extended_segment.columns:\n",
    "        extended_segment['average_trade_price'] = np.where(\n",
    "            extended_segment['volume'].diff() != 0,\n",
    "            (extended_segment['amount'].diff() / extended_segment['volume'].diff()).fillna(0),\n",
    "            extended_segment['mid_price']\n",
    "        )\n",
    "    else:\n",
    "        extended_segment['average_trade_price'] = np.where(\n",
    "            extended_segment['volume'].diff() != 0,\n",
    "            (extended_segment['amount'].diff() / extended_segment['volume'].diff()).fillna(0),\n",
    "            extended_segment['average_trade_price'].shift(1).fillna(0)\n",
    "        )\n",
    "\n",
    "    extended_segment['mid_price_basis'] = extended_segment['average_trade_price'] - extended_segment['mid_price']\n",
    "\n",
    "    # Drop intermediary derived feature columns\n",
    "    intermediary_columns = [\n",
    "        'total_bid_volume', 'total_ask_volume', 'mid_price', 'average_trade_price'\n",
    "    ]\n",
    "    extended_segment = extended_segment.drop(columns=intermediary_columns)\n",
    "\n",
    "    # Ensure there are no NaN values\n",
    "    assert not extended_segment.isnull().values.any(), \"There are NaN values in the derived features\"\n",
    "    assert(np.isnan(extended_segment).sum().sum() == 0)\n",
    "\n",
    "\n",
    "def add_factors(extended_segment, short_period, long_period, signal_period, period):\n",
    "    # Compute Factors: MA & MACD\n",
    "    for i in range(len(period)):\n",
    "      # Calculate MA\n",
    "      t = period[i]\n",
    "      extended_segment[f'ma({t})'] = moving_average(extended_segment['last_price'], t)\n",
    "      extended_segment[f'ma({t})'] = extended_segment[f'ma({t})'].fillna(method='ffill')\n",
    "\n",
    "      # Calculate MACD\n",
    "      a = short_period[i]\n",
    "      b = long_period[i]\n",
    "      c = signal_period[i]\n",
    "      macd_line, signal_line, macd_histogram = calculate_macd(extended_segment['last_price'], a, b, c)\n",
    "      extended_segment[f'macd_line({a},{b},{c})'] = macd_line\n",
    "      extended_segment[f'signal_line({a},{b},{c})'] = signal_line\n",
    "      extended_segment[f'macd_histogram({a},{b},{c})'] = macd_histogram\n",
    "\n",
    "    print(extended_segment.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "DVuKsKrMC7iP",
    "outputId": "907ed828-ba3b-453e-9a0f-f94d442eb1c5"
   },
   "outputs": [],
   "source": [
    "# Params\n",
    "dataset_filename = 'INE.sc2010'\n",
    "intervals = [\n",
    "    ('21:00:00', '02:30:00'),\n",
    "    ('09:00:00', '10:15:00'),\n",
    "    ('10:30:00', '11:30:00'),\n",
    "    ('13:30:00', '15:00:00')\n",
    "]\n",
    "configs_filename = 'configs'\n",
    "\n",
    "# Load configs file\n",
    "configs = load_configs(configs_filename)\n",
    "clear_gpu_cache()\n",
    "\n",
    "# Read data\n",
    "# data = pd.read_csv('data/' + dataset_filename + '.csv')\n",
    "data = pd.read_csv(f'data/{dataset_filename}.csv')\n",
    "data['datetime'] = pd.to_datetime(data['datetime'])\n",
    "\n",
    "# Set seed\n",
    "set_seed(42)\n",
    "\n",
    "with cProfile.Profile() as pr:\n",
    "    # Only include data within the specified intervals\n",
    "    data_filtered = filter_data_by_intervals(data, intervals)\n",
    "    # pr.print_stats()\n",
    "\n",
    "    # Make sure there are no values outside the given time intervals\n",
    "    assert_time_intervals(data_filtered, intervals)\n",
    "    # pr.print_stats()\n",
    "\n",
    "    # Plot trading volume data\n",
    "    plot_volume(data_filtered, 'Daily Trading Volume of SC2010 Stocks')\n",
    "\n",
    "    # Extract the main contract\n",
    "    # data_filtered = data_filtered.copy() # Avoid SettingWithCopyWarning\n",
    "    # pr.print_stats()\n",
    "    data_filtered.iloc[:, 1:] = data_filtered.iloc[:, 1:].astype(np.float32)\n",
    "    # pr.print_stats()\n",
    "    extended_segment = extract_main_contract(data_filtered)\n",
    "    # pr.print_stats()\n",
    "\n",
    "    # Plot main contract segment\n",
    "    plot_volume(extended_segment, 'Trading Volume of Main Contract Segment')\n",
    "    # pr.print_stats()\n",
    "\n",
    "    # Set index of the resulting dataframe\n",
    "    extended_segment.set_index('datetime', inplace=True)\n",
    "    # pr.print_stats()\n",
    "\n",
    "    # Make sure there are no values outside the given time intervals\n",
    "    assert_time_intervals(extended_segment, intervals)\n",
    "    # pr.print_stats()\n",
    "\n",
    "    # Extract needed hyperparams\n",
    "    input_size = configs['input_size']\n",
    "    num_steps = configs['num_steps']\n",
    "    normalize = configs['normalize']\n",
    "    batch_size = configs['batch_size']\n",
    "\n",
    "    # Add derived features\n",
    "    add_derived_features(extended_segment)\n",
    "\n",
    "    # Add factors\n",
    "    period_labels = np.array(['2.5s', '5s', '7.5s', '10s'])\n",
    "    period = np.array([5, 10, 15, 20])\n",
    "    short_period = period\n",
    "    long_period = period + 10\n",
    "    signal_period = 2 * period\n",
    "\n",
    "    add_factors(extended_segment, short_period, long_period, signal_period, period)\n",
    "    # pr.print_stats()\n",
    "\n",
    "    # Plot closing prices with factors\n",
    "    plot_prices_with_ma(extended_segment, period, period_labels)\n",
    "    plot_prices_with_macd(extended_segment, short_period, long_period, signal_period)\n",
    "\n",
    "    # Normalize data\n",
    "    extended_segment = normalize_data(extended_segment)\n",
    "    assert(extended_segment.isna().sum().sum() == 0)\n",
    "\n",
    "    # Create sequences based on the extended_segment\n",
    "    extended_segment, train_loader, val_loader, test_loader, num_features = create_sequences(extended_segment, num_steps, input_size, normalize, val_split=0.1, test_split=0.1, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZYSFG2CvRdl3"
   },
   "source": [
    "## RNN Model Definition \n",
    "\n",
    "Include quantized components when Quantized-Aware Training (QAT) enabled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "97w6HrsKqROK"
   },
   "outputs": [],
   "source": [
    "def convert_to_labels(val, flat_gap=0.01):\n",
    "    return 2 if val > flat_gap else 0 if val < -flat_gap else 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z6Jc4p_Rqguf"
   },
   "outputs": [],
   "source": [
    "def classification_accuracy(y_pred, y_true):\n",
    "    y_pred_labels = torch.tensor([convert_to_labels(y) for y in torch.flatten(y_pred)])\n",
    "    y_true_labels = torch.tensor([convert_to_labels(y) for y in torch.flatten(y_true)])\n",
    "    return torch.sum(y_pred_labels == y_true_labels) / len(y_true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to fake quantize input to int8\n",
    "def fake_quantize(x, scale, zero_point, qmin=-128, qmax=127):\n",
    "    x = x.to(torch.float32)\n",
    "    qx = torch.round(x / scale + zero_point).clamp(qmin, qmax)\n",
    "    return qx\n",
    "\n",
    "# Quantize per channel and return int8 tensor\n",
    "def fake_quantize_per_channel(tensor, scales, zero_points, axis=0, qmin=-128, qmax=127):\n",
    "    scales = scales.unsqueeze(axis).expand_as(tensor)\n",
    "    zero_points = zero_points.unsqueeze(axis).expand_as(tensor)\n",
    "    quantized_tensor = torch.round(tensor / scales + zero_points).clamp(qmin, qmax)\n",
    "    return quantized_tensor\n",
    "\n",
    "def update_scale_and_zero_point(x, num_bits=8):\n",
    "    qmin, qmax = -(1 << (num_bits - 1)), (1 << (num_bits - 1)) - 1\n",
    "\n",
    "    min_val, max_val = x.min().item(), x.max().item()\n",
    "\n",
    "    scale = (max_val - min_val) / (qmax - qmin) if min_val != max_val else 1.0\n",
    "    zero_point = qmin - min_val / scale\n",
    "    zero_point = torch.round(torch.tensor(zero_point)).int().clamp(qmin, qmax)\n",
    "    \n",
    "    return scale, zero_point\n",
    "\n",
    "def update_scale_and_zero_point(x, num_bits=8):\n",
    "    qmin, qmax = -(1 << (num_bits - 1)), (1 << (num_bits - 1)) - 1  # [-128, 127] for 8-bit\n",
    "\n",
    "    min_val, max_val = x.min().item(), x.max().item()\n",
    "\n",
    "    if min_val == max_val:\n",
    "        scale = 1.0\n",
    "        zero_point = 0\n",
    "    else:\n",
    "        scale = (max_val - min_val) / (qmax - qmin)\n",
    "        zero_point = qmin - min_val / scale\n",
    "        zero_point = torch.round(torch.tensor(zero_point)).int()\n",
    "        zero_point = torch.clamp(zero_point, qmin, qmax)\n",
    "    \n",
    "    return scale, zero_point\n",
    "\n",
    "def update_scale_and_zero_point_per_channel(tensor, axis=0, num_bits=8):\n",
    "    qmin, qmax = -(1 << (num_bits - 1)), (1 << (num_bits - 1)) - 1\n",
    "    tensor_min = tensor.min(dim=axis, keepdim=True).values\n",
    "    tensor_max = tensor.max(dim=axis, keepdim=True).values\n",
    "\n",
    "    scale = (tensor_max - tensor_min) / (qmax - qmin)\n",
    "    scale = torch.where(scale == 0, torch.ones_like(scale), scale)\n",
    "    zero_point = torch.round(qmin - tensor_min / scale).int().clamp(qmin, qmax)\n",
    "\n",
    "    return scale.squeeze(dim=axis), zero_point.squeeze(dim=axis)\n",
    "\n",
    "def quantize_tensor(tensor, scale, zero_point, qmin=-128, qmax=127):\n",
    "    q_tensor = torch.round(tensor / scale + zero_point).clamp(qmin, qmax)\n",
    "    return q_tensor\n",
    "\n",
    "# Quantize tensor per channel\n",
    "def quantize_per_channel(tensor, axis=0, num_bits=8):\n",
    "    scales, zero_points = update_scale_and_zero_point_per_channel(tensor, axis=axis, num_bits=num_bits)\n",
    "    quantized_tensor = fake_quantize_per_channel(tensor, scales, zero_points, axis=axis, qmin=-128, qmax=127)\n",
    "    return quantized_tensor, scales, zero_points\n",
    "\n",
    "def dequantize_tensor(q_tensor, scale, zero_point):\n",
    "    if not isinstance(scale, torch.Tensor):\n",
    "        scale = torch.tensor(scale, dtype=torch.float32, device=q_tensor.device)\n",
    "    if not isinstance(zero_point, torch.Tensor):\n",
    "        zero_point = torch.tensor(zero_point, dtype=torch.float32, device=q_tensor.device)\n",
    "\n",
    "    tensor = (q_tensor.to(torch.float32) - zero_point) * scale\n",
    "\n",
    "    return tensor\n",
    "\n",
    "# Export parameters (weights, scales, zero points) from model\n",
    "def export_model_parameters(model, filepath):\n",
    "    model_params = {}\n",
    "\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.dim() > 0:  # Ensure we're not trying to quantize a 0-dim tensor\n",
    "            q_tensor, scales, zero_points = quantize_per_channel(param)\n",
    "            model_params[name] = {\n",
    "                \"weights\": q_tensor.tolist(),\n",
    "                \"scales\": scales.tolist(),\n",
    "                \"zero_points\": zero_points.tolist()\n",
    "            }\n",
    "        else:\n",
    "            # For 0-dim tensors, handle separately\n",
    "            model_params[name] = {\n",
    "                \"weights\": [param.item()],\n",
    "                \"scales\": [1.0],\n",
    "                \"zero_points\": [0]\n",
    "            }\n",
    "\n",
    "    with open(filepath, 'w') as f:\n",
    "        json.dump(model_params, f, indent=4)\n",
    "\n",
    "def log_tensor_info(tensor, name):\n",
    "    print(f\"{name} shape: {tensor.shape}\")\n",
    "    print(f\"{name} min: {tensor.min()}, max: {tensor.max()}\")\n",
    "    print(f\"{name} mean: {tensor.to(torch.float32).mean()}\")\n",
    "    assert not torch.isnan(tensor).any(), f\"{name} contains NaN values!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLayerNorm(nn.Module):\n",
    "    def __init__(self, normalized_shape):\n",
    "        super(CustomLayerNorm, self).__init__()\n",
    "        self.normalized_shape = normalized_shape\n",
    "        self.eps = 1e-5\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
    "        return (x - mean) / torch.sqrt(var + self.eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FakeQuantizationFunction(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x, scale, zero_point):\n",
    "        return fake_quantize(x, scale, zero_point)\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        # Pass-through gradient to avoid quantization noise during backpropagation\n",
    "        return grad_output, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kTpoDSrwJxeA"
   },
   "outputs": [],
   "source": [
    "# Custom LSTM Cell with quantization support\n",
    "class CustomLSTMCell(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, dropout_rate=0.0, quantize=False):\n",
    "        super(CustomLSTMCell, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.quantize = quantize\n",
    "\n",
    "        self.W_i = nn.Parameter(torch.randn(hidden_dim, input_dim))\n",
    "        self.U_i = nn.Parameter(torch.randn(hidden_dim, hidden_dim))\n",
    "        self.b_i = nn.Parameter(torch.zeros(hidden_dim))\n",
    "\n",
    "        self.W_f = nn.Parameter(torch.randn(hidden_dim, input_dim))\n",
    "        self.U_f = nn.Parameter(torch.randn(hidden_dim, hidden_dim))\n",
    "        self.b_f = nn.Parameter(torch.zeros(hidden_dim))\n",
    "\n",
    "        self.W_c = nn.Parameter(torch.randn(hidden_dim, input_dim))\n",
    "        self.U_c = nn.Parameter(torch.randn(hidden_dim, hidden_dim))\n",
    "        self.b_c = nn.Parameter(torch.zeros(hidden_dim))\n",
    "\n",
    "        self.W_o = nn.Parameter(torch.randn(hidden_dim, input_dim))\n",
    "        self.U_o = nn.Parameter(torch.randn(hidden_dim, hidden_dim))\n",
    "        self.b_o = nn.Parameter(torch.zeros(hidden_dim))\n",
    "\n",
    "        self.batch_norm = nn.BatchNorm1d(hidden_dim)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        for name, param in self.named_parameters():\n",
    "            if 'W_' in name or 'U_' in name:\n",
    "                nn.init.xavier_uniform_(param)\n",
    "            elif 'b_' in name:\n",
    "                nn.init.constant_(param, 0.0)\n",
    "\n",
    "    def quantize_and_dequantize(self, x, scale, zero_point):\n",
    "        return FakeQuantizationFunction.apply(x, scale, zero_point)\n",
    "\n",
    "    def forward(self, x, h, c):\n",
    "        if self.quantize:\n",
    "            scale_x, zero_point_x = update_scale_and_zero_point(x)\n",
    "            x_q = self.quantize_and_dequantize(x, scale_x, zero_point_x)\n",
    "\n",
    "            W_i, scale_w_i, zero_point_w_i = quantize_per_channel(self.W_i, axis=0)\n",
    "            U_i, scale_u_i, zero_point_u_i = quantize_per_channel(self.U_i, axis=0)\n",
    "            b_i_q = quantize_tensor(self.b_i, scale_w_i.mean(), zero_point_w_i.float().mean())\n",
    "            i_t = torch.sigmoid(self.dropout(torch.mm(x_q, W_i.float().t()) + torch.mm(h, U_i.float().t()) + b_i_q))\n",
    "\n",
    "            W_f, scale_w_f, zero_point_w_f = quantize_per_channel(self.W_f, axis=0)\n",
    "            U_f, scale_u_f, zero_point_u_f = quantize_per_channel(self.U_f, axis=0)\n",
    "            b_f_q = quantize_tensor(self.b_f, scale_w_f.mean(), zero_point_w_f.float().mean())\n",
    "            f_t = torch.sigmoid(self.dropout(torch.mm(x_q, W_f.float().t()) + torch.mm(h, U_f.float().t()) + b_f_q))\n",
    "\n",
    "            W_o, scale_w_o, zero_point_w_o = quantize_per_channel(self.W_o, axis=0)\n",
    "            U_o, scale_u_o, zero_point_u_o = quantize_per_channel(self.U_o, axis=0)\n",
    "            b_o_q = quantize_tensor(self.b_o, scale_w_o.mean(), zero_point_w_o.float().mean())\n",
    "            o_t = torch.sigmoid(self.dropout(torch.mm(x_q, W_o.float().t()) + torch.mm(h, U_o.float().t()) + b_o_q))\n",
    "\n",
    "            W_c, scale_w_c, zero_point_w_c = quantize_per_channel(self.W_c, axis=0)\n",
    "            U_c, scale_u_c, zero_point_u_c = quantize_per_channel(self.U_c, axis=0)\n",
    "            b_c_q = quantize_tensor(self.b_c, scale_w_c.mean(), zero_point_w_c.float().mean())\n",
    "            c_tilda = torch.tanh(self.dropout(torch.mm(x_q, W_c.float().t()) + torch.mm(h, U_c.float().t()) + b_c_q))\n",
    "\n",
    "            c_next = f_t * c + i_t * c_tilda\n",
    "            h_next = o_t * torch.tanh(self.batch_norm(c_next))\n",
    "\n",
    "            return h_next, c_next\n",
    "        else:\n",
    "            i_t = torch.sigmoid(self.dropout(torch.mm(x, self.W_i.t()) + torch.mm(h, self.U_i.t()) + self.b_i))\n",
    "            f_t = torch.sigmoid(self.dropout(torch.mm(x, self.W_f.t()) + torch.mm(h, self.U_f.t()) + self.b_f))\n",
    "            o_t = torch.sigmoid(self.dropout(torch.mm(x, self.W_o.t()) + torch.mm(h, self.U_o.t()) + self.b_o))\n",
    "            c_tilda = torch.tanh(self.dropout(torch.mm(x, self.W_c.t()) + torch.mm(h, self.U_c.t()) + self.b_c))\n",
    "\n",
    "            c_next = f_t * c + i_t * c_tilda\n",
    "            h_next = o_t * torch.tanh(self.batch_norm(c_next))\n",
    "\n",
    "            return h_next, c_next\n",
    "\n",
    "class CustomLSTM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, dropout_rate=0.0, quantize=False):\n",
    "        super(CustomLSTM, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.quantize = quantize\n",
    "\n",
    "        self.layers = nn.ModuleList([\n",
    "            CustomLSTMCell(input_dim if i == 0 else hidden_dim, hidden_dim, dropout_rate, quantize)\n",
    "            for i in range(num_layers)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len, _ = x.size()\n",
    "        hidden_states = [self.init_hidden(batch_size) for _ in range(self.num_layers)]\n",
    "    \n",
    "        outputs = []\n",
    "    \n",
    "        for t in range(seq_len):\n",
    "            x_t = x[:, t, :] \n",
    "            # Pass through each layer\n",
    "            for i, layer in enumerate(self.layers):\n",
    "                h, c = hidden_states[i]\n",
    "                # For the first layer, use x_t; for subsequent layers, use h from the last\n",
    "                x_t, new_c = layer(x_t, h, c)\n",
    "                hidden_states[i] = (x_t, new_c)\n",
    "            # Append output from last layer\n",
    "            outputs.append(x_t)\n",
    "    \n",
    "        # Stack outputs to get the final shape (batch_size, num_steps, hidden_dim)\n",
    "        outputs = torch.stack(outputs, dim=1)\n",
    "        return outputs\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        h = torch.zeros(batch_size, self.hidden_dim)\n",
    "        c = torch.zeros(batch_size, self.hidden_dim)\n",
    "        return h, c\n",
    "    \n",
    "    def set_quantization(self, quantize):\n",
    "        self.quantize = quantize\n",
    "        for layer in self.layers:\n",
    "            layer.quantize = quantize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ckdaPSaxJxhM"
   },
   "outputs": [],
   "source": [
    "# Custom GRU Cell with quantization support\n",
    "class CustomGRUCell(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, dropout_rate=0.1, quantize=False):\n",
    "        super(CustomGRUCell, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.quantize = quantize\n",
    "\n",
    "        self.W_z = nn.Parameter(torch.randn(hidden_dim, input_dim))\n",
    "        self.U_z = nn.Parameter(torch.randn(hidden_dim, hidden_dim))\n",
    "        self.b_z = nn.Parameter(torch.zeros(hidden_dim))\n",
    "\n",
    "        self.W_r = nn.Parameter(torch.randn(hidden_dim, input_dim))\n",
    "        self.U_r = nn.Parameter(torch.randn(hidden_dim, hidden_dim))\n",
    "        self.b_r = nn.Parameter(torch.zeros(hidden_dim))\n",
    "\n",
    "        self.W_h = nn.Parameter(torch.randn(hidden_dim, input_dim))\n",
    "        self.U_h = nn.Parameter(torch.randn(hidden_dim, hidden_dim))\n",
    "        self.b_h = nn.Parameter(torch.zeros(hidden_dim))\n",
    "\n",
    "        self.batch_norm = nn.BatchNorm1d(hidden_dim)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        for name, param in self.named_parameters():\n",
    "            if 'W_' in name or 'U_' in name:\n",
    "                nn.init.xavier_uniform_(param)\n",
    "            elif 'b_' in name:\n",
    "                nn.init.constant_(param, 0.0)\n",
    "    \n",
    "    def quantize_and_dequantize(self, x, scale, zero_point):\n",
    "        return FakeQuantizationFunction.apply(x, scale, zero_point)\n",
    "    \n",
    "    def forward(self, x, h):\n",
    "        if self.quantize:\n",
    "            scale_x, zero_point_x = update_scale_and_zero_point(x)\n",
    "            x_q = self.quantize_and_dequantize(x, scale_x, zero_point_x)\n",
    "\n",
    "            W_z_q, scale_w_z, zero_point_w_z = quantize_per_channel(self.W_z, axis=0)\n",
    "            U_z_q, scale_u_z, zero_point_u_z = quantize_per_channel(self.U_z, axis=0)\n",
    "            b_z_q = quantize_tensor(self.b_z, scale_w_z.mean(), zero_point_w_z.float().mean())\n",
    "            z_t = torch.sigmoid(torch.mm(x_q, W_z_q.float().t()) + torch.mm(h, U_z_q.float().t()) + b_z_q)\n",
    "\n",
    "            W_r_q, scale_w_r, zero_point_w_r = quantize_per_channel(self.W_r, axis=0)\n",
    "            U_r_q, scale_u_r, zero_point_u_r = quantize_per_channel(self.U_r, axis=0)\n",
    "            b_r_q = quantize_tensor(self.b_r, scale_w_r.mean(), zero_point_w_r.float().mean())\n",
    "            r_t = torch.sigmoid(torch.mm(x_q, W_r_q.float().t()) + torch.mm(h, U_r_q.float().t()) + b_r_q)\n",
    "\n",
    "            W_h_q, scale_w_h, zero_point_w_h = quantize_per_channel(self.W_h, axis=0)\n",
    "            U_h_q, scale_u_h, zero_point_u_h = quantize_per_channel(self.U_h, axis=0)\n",
    "            b_h_q = quantize_tensor(self.b_h, scale_w_h.mean(), zero_point_w_h.float().mean())\n",
    "            h_tilda = torch.tanh(torch.mm(x_q, W_h_q.float().t()) + r_t * torch.mm(h, U_h_q.float().t()) + b_h_q)\n",
    "\n",
    "            h_next = (1 - z_t) * h + z_t * h_tilda\n",
    "            h_next = self.batch_norm(h_next)\n",
    "            return h_next\n",
    "        else:\n",
    "            z_t = torch.sigmoid(torch.mm(x, self.W_z.t()) + torch.mm(h, self.U_z.t()) + self.b_z)\n",
    "            r_t = torch.sigmoid(torch.mm(x, self.W_r.t()) + torch.mm(h, self.U_r.t()) + self.b_r)\n",
    "            h_tilda = torch.tanh(torch.mm(x, self.W_h.t()) + r_t * torch.mm(h, self.U_h.t()) + self.b_h)\n",
    "            h_next = (1 - z_t) * h + z_t * h_tilda\n",
    "            h_next = self.batch_norm(h_next)\n",
    "            return h_next\n",
    "\n",
    "\n",
    "class CustomGRU(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, dropout_rate=0.0, quantize=False):\n",
    "        super(CustomGRU, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.quantize = quantize\n",
    "\n",
    "        self.layers = nn.ModuleList([\n",
    "            CustomGRUCell(input_dim if i == 0 else hidden_dim, hidden_dim, dropout_rate, quantize)\n",
    "            for i in range(num_layers)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len, _ = x.size()\n",
    "        hidden_states = [self.init_hidden(batch_size) for _ in range(self.num_layers)]\n",
    "    \n",
    "        outputs = []\n",
    "    \n",
    "        for t in range(seq_len):\n",
    "            x_t = x[:, t, :] \n",
    "            # Pass through each layer\n",
    "            for i, layer in enumerate(self.layers):\n",
    "                h = hidden_states[i]\n",
    "                # For the first layer, use x_t; for subsequent layers, use h from the last\n",
    "                x_t = layer(x_t, h)\n",
    "                hidden_states[i] = x_t\n",
    "            # Append output from last layer\n",
    "            outputs.append(x_t)\n",
    "    \n",
    "        # Stack outputs to get the final shape (batch_size, num_steps, hidden_dim)\n",
    "        outputs = torch.stack(outputs, dim=1)\n",
    "        return outputs\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        return torch.zeros(batch_size, self.hidden_dim)\n",
    "\n",
    "    def set_quantization(self, quantize):\n",
    "        self.quantize = quantize\n",
    "        for layer in self.layers:\n",
    "            layer.quantize = quantize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLinear(nn.Module):\n",
    "    def __init__(self, in_features, out_features, bias=True, quantize=False):\n",
    "        super(CustomLinear, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.quantize = quantize\n",
    "        self.weight = nn.Parameter(torch.Tensor(out_features, in_features))\n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(torch.Tensor(out_features))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        self.quantized = False\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        nn.init.xavier_uniform_(self.weight)\n",
    "        if self.bias is not None:\n",
    "            nn.init.constant_(self.bias, 0.0)\n",
    "\n",
    "    def quantize_and_dequantize(self, x, scale, zero_point):\n",
    "        return FakeQuantizationFunction.apply(x, scale, zero_point)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Reshape x to 2D: (batch_size * num_steps, input_size)\n",
    "        batch_size, num_steps, _ = x.size()\n",
    "        x = x.view(-1, self.in_features)\n",
    "\n",
    "        output = torch.mm(x, self.weight.t())\n",
    "        if self.bias is not None:\n",
    "            output += self.bias\n",
    "\n",
    "        # Reshape output back to 3D: (batch_size, num_steps, out_features)\n",
    "        output = output.view(batch_size, num_steps, self.out_features)\n",
    "\n",
    "        return output\n",
    "\n",
    "    def set_quantization(self, quantize):\n",
    "        self.quantize = quantize\n",
    "        if self.quantize:\n",
    "            self.scale_w, self.zero_point_w = None, None  # Initialize as None initially"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomRNNModel(nn.Module):\n",
    "    def __init__(self, num_steps=20, input_size=10, hidden_units=128, num_layers=3, dropout_rate=0.1, quantize=False, rnn_type='lstm'):\n",
    "        super(CustomRNNModel, self).__init__()\n",
    "        self.quantize = quantize\n",
    "        self.rnn_type = rnn_type\n",
    "        \n",
    "        # Select RNN type\n",
    "        if rnn_type == 'lstm':\n",
    "            self.rnn = CustomLSTM(input_size * num_features, hidden_units, num_layers, dropout_rate=dropout_rate, quantize=quantize)\n",
    "        elif rnn_type == 'gru':\n",
    "            self.rnn = CustomGRU(input_size * num_features, hidden_units, num_layers, dropout_rate=dropout_rate, quantize=quantize)\n",
    "        \n",
    "        self.fc = CustomLinear(hidden_units, input_size, quantize=quantize)  # CustomLinear layer with quantization\n",
    "        \n",
    "        self.init_weights()\n",
    "    \n",
    "        # Assign names to RNN layers for easy quantization handling\n",
    "        for layer_idx, layer in enumerate(self.rnn.layers):\n",
    "            for name, param in layer.named_parameters():\n",
    "                name = name.replace('.', '_')\n",
    "                self.register_buffer(f'rnn{layer_idx}_{name}', param)\n",
    "\n",
    "        # Assign names to linear layers\n",
    "        for name, param in self.fc.named_parameters():\n",
    "            name = name.replace('.', '_')\n",
    "            self.register_buffer(f'fc_{name}', param)\n",
    "        \n",
    "    def init_weights(self):\n",
    "        for name, param in self.named_parameters():\n",
    "            if 'fc' in name:\n",
    "                if len(param.shape) >= 2:\n",
    "                    nn.init.xavier_uniform_(param)\n",
    "            elif 'b' in name:\n",
    "                nn.init.constant_(param, 0.0)\n",
    "\n",
    "    def set_quantization_bits(self, num_bits):\n",
    "        self.quantization_bits = num_bits\n",
    "\n",
    "    def quantize(self, x):\n",
    "        scale = 2 ** (self.quantization_bits - 1) - 1\n",
    "        return torch.round(x * scale) / scale\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Reshape input to batch_size, num_steps, input_size\n",
    "        batch_size, num_steps, input_size, num_features = x.shape\n",
    "        x = torch.reshape(x, (batch_size, num_steps, input_size * num_features))\n",
    "        \n",
    "        # Pass input through RNN\n",
    "        rnn_output = self.rnn(x)\n",
    "        \n",
    "        # Apply the fully connected layer on the output of the last time step\n",
    "        output = self.fc(rnn_output)\n",
    "\n",
    "        output = torch.reshape(output, (batch_size, num_steps, input_size))\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def set_quantization(self, quantize):\n",
    "        self.quantize = quantize\n",
    "        self.rnn.set_quantization(quantize)\n",
    "        self.fc.set_quantization(quantize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(y_pred, y_true, y_pred_quantized, criterion, alpha=1):\n",
    "    \"\"\" Custom loss function combining original loss and quantization loss. \"\"\"\n",
    "    classification_loss = criterion(y_pred, y_true)\n",
    "    quantization_loss = criterion(y_pred, y_pred_quantized)\n",
    "    total_loss = classification_loss + alpha * quantization_loss\n",
    "    return total_loss\n",
    "\n",
    "def adjust_quantization_params(epoch, total_epochs):\n",
    "    # Faster reduction of bit precision\n",
    "    start_bits = 16\n",
    "    end_bits = 8\n",
    "    total_steps = total_epochs // 10  # Adjust every 10% of total epochs\n",
    "    step_size = (start_bits - end_bits) / total_steps\n",
    "    num_bits = start_bits - int(step_size * (epoch // (total_epochs // total_steps)))\n",
    "    return max(end_bits, num_bits)  # Ensure we do not go below end_bits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7x14GluDn5Yt"
   },
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, config, device, print_freq=10):\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=config['init_learning_rate'], weight_decay=1e-4)  # Using AdamW\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=config['learning_rate_decay'])  \n",
    "    \n",
    "    early_stop_patience = config['early_stop_patience']\n",
    "    best_val_loss = float('inf')\n",
    "    patience = 0\n",
    "    scaler = torch.cuda.amp.GradScaler()  # For mixed precision\n",
    "\n",
    "    for epoch in tqdm(range(config['max_epochs']), position=0, leave=True):\n",
    "        # Adjust quantization parameters for the current epoch\n",
    "        num_bits = adjust_quantization_params(epoch, config['max_epochs'])\n",
    "        model.set_quantization_bits(num_bits)  # Update the model's quantization bit precision\n",
    "\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        \n",
    "        for i, (x_batch, y_batch) in tqdm(enumerate(train_loader), position=0, leave=True):\n",
    "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Mixed precision training\n",
    "            with torch.cuda.amp.autocast():\n",
    "                # Forward pass with and without quantization\n",
    "                y_pred = model(x_batch)\n",
    "                model.set_quantization(True)  # Enable quantization\n",
    "                y_pred_quantized = model(x_batch)\n",
    "                model.set_quantization(False)  # Disable quantization for future iterations\n",
    "                loss = custom_loss(y_pred, y_batch, y_pred_quantized, criterion)\n",
    "\n",
    "            scaler.scale(loss).backward(retain_graph=True)  # Use scaled loss for backward pass\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # Gradient clipping\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "            if i % print_freq == 0:\n",
    "                print(f'Epoch [{epoch + 1}/{config[\"max_epochs\"]}], Step [{i + 1}/{len(train_loader)}], Loss: {loss.item()}')\n",
    "                print('Training classification:', classification_accuracy(y_pred, y_batch).item())\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for i, (x_batch, y_batch) in tqdm(enumerate(val_loader), position=0, leave=True):\n",
    "                x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "                with torch.cuda.amp.autocast():\n",
    "                    # Forward pass with and without quantization\n",
    "                    y_pred = model(x_batch)\n",
    "                    model.set_quantization(True)  # Enable quantization\n",
    "                    y_pred_quantized = model(x_batch)\n",
    "                    model.set_quantization(False)  # Disable quantization for future iterations\n",
    "                    loss = custom_loss(y_pred, y_batch, y_pred_quantized, criterion)\n",
    "\n",
    "                val_loss += loss.item()\n",
    "                \n",
    "                if i % print_freq == 0:\n",
    "                    print('Validation classification:', classification_accuracy(y_pred, y_batch).item())\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        print(f'Epoch [{epoch + 1}/{config[\"max_epochs\"]}], Validation Loss: {val_loss}')\n",
    "        \n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience = 0\n",
    "            print('Saving model with best validation loss...')\n",
    "            torch.save(model.state_dict(), f'models/SC2010_{model.rnn_type}_model.pth')\n",
    "        else:\n",
    "            patience += 1\n",
    "            if patience >= early_stop_patience:\n",
    "                print('Early stopping due to no improvement in validation loss.')\n",
    "                break\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "    print('Training finished.')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "noAjxW3sppPC"
   },
   "outputs": [],
   "source": [
    "def load_model(model, rnn_type, device):\n",
    "    model_path = f'models/SC2010_{rnn_type}_model.pth' \n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.to(device)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vFfMKnlIPjmo"
   },
   "outputs": [],
   "source": [
    "def train_or_load_model(configs, train_loader, val_loader, rnn_type, device):\n",
    "    # Define model & load into device\n",
    "    # model = CustomRNNModel(rnn_type=rnn_type, num_steps=configs['num_steps'], input_size=configs['input_size'], hidden_units=configs[rnn_type][f'{rnn_type}_units'], num_layers=configs[rnn_type][f'{rnn_type}_layers'], dropout_rate=configs[rnn_type]['dropout_rate'], dense_units=configs[rnn_type]['dense_units'], quantize=quantize)\n",
    "    model = CustomRNNModel(rnn_type=rnn_type, num_steps=configs['num_steps'], input_size=configs['input_size'], hidden_units=configs[rnn_type][f'{rnn_type}_units'], num_layers=configs[rnn_type][f'{rnn_type}_layers'], dropout_rate=configs[rnn_type]['dropout_rate'])\n",
    "    model.to(device)\n",
    "    \n",
    "    if configs[rnn_type]['pretrain']:\n",
    "        # Train the model (and save the best iteration) \n",
    "        model = train_model(model, train_loader, val_loader, configs[rnn_type], device)\n",
    "        \n",
    "    # Load the model (with the best iteration, or via pre-trained)\n",
    "    model = load_model(model, rnn_type, device)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-1-42q_WQxoq"
   },
   "outputs": [],
   "source": [
    "def mean_percent_diff(quant_outputs, noquant_outputs):\n",
    "    total_abs_diff = 0.0\n",
    "    total_elements = 0\n",
    "    \n",
    "    # Iterate through each batch in the list\n",
    "    for i in range(len(test_preds_lstm_noquant)):\n",
    "        noquant = noquant_outputs[i]\n",
    "        quant = quant_outputs[i]\n",
    "        \n",
    "        # Ensure shapes match\n",
    "        if noquant.shape != quant.shape:\n",
    "            raise ValueError(f\"Shape mismatch: {noquant.shape} vs {quant.shape}\")\n",
    "        \n",
    "        # Calculate absolute differences\n",
    "        abs_diff = np.abs(noquant - quant)\n",
    "        \n",
    "        # Calculate percent differences\n",
    "        percent_diff = (abs_diff / (np.abs(noquant) + 1e-8)) * 100\n",
    "        \n",
    "        # Aggregate differences\n",
    "        total_abs_diff += np.sum(percent_diff)\n",
    "        total_elements += np.size(percent_diff)\n",
    "    \n",
    "    # Calculate mean percent difference\n",
    "    percent_diff = total_abs_diff / total_elements   \n",
    "    return percent_diff\n",
    "\n",
    "\n",
    "# Evaluate the model\n",
    "def evaluate_model(model, test_loader, device, quantize=False):\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "    model.quantize = quantize\n",
    "\n",
    "    test_loss = 0.0\n",
    "    test_accuracy = 0.0\n",
    "    \n",
    "    preds = []\n",
    "\n",
    "    # Disable gradient computation during evaluation\n",
    "    with torch.no_grad():\n",
    "        # Iterate over test set data\n",
    "        for i, (x_batch, y_batch) in tqdm(enumerate(test_loader), position=0, leave=True):\n",
    "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "            y_pred = model(x_batch)\n",
    "            loss = nn.MSELoss()(y_pred, y_batch)\n",
    "            preds.append(y_pred.cpu().numpy())  # Ensure data is on CPU for numpy operations\n",
    "            test_loss += loss.item()\n",
    "            test_accuracy += classification_accuracy(y_pred, y_batch).item()\n",
    "    \n",
    "    test_loss = test_loss / len(test_loader)\n",
    "    test_accuracy = test_accuracy / len(test_loader)\n",
    "\n",
    "    print(\"Test Loss:\", test_loss)\n",
    "    print('Test Classification Accuracy:', test_accuracy)\n",
    "    \n",
    "    return preds, test_loss, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wtfCK8cen5dZ"
   },
   "outputs": [],
   "source": [
    "# Set up device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset configs\n",
    "configs = load_configs('configs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SXCWMY1ERPb4"
   },
   "source": [
    "## Training + Evaluation Results:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rnn_type = 'lstm'\n",
    "\n",
    "# Training\n",
    "model_lstm = train_or_load_model(configs, train_loader, val_loader, rnn_type, device)\n",
    "\n",
    "# Export model parameters to JSON file\n",
    "export_model_parameters(model_lstm, f'models/SC2010_quantized_{rnn_type}_parameters.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Without Quantization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "95eca35a46a14aa4abf7c91b1ccee065",
      "01289697a46a4749808002f2a6eaaf73",
      "9ff6b3cf75b746f5a11dc7a7eadc2009",
      "e86b3864d880446081ae53689493f24e",
      "c275aca6f2c84125923cbd7246786078",
      "b1f95063a92b48e0b5ca86e7a6716236",
      "abf1a93ee34843578018f72eeb64a9ea",
      "18429f5771a24ae1a72150c16e7f97d3",
      "a583468ab883499e9d8cc9dadac9c597",
      "497e7dd3069a4b5dbc883e4695332963",
      "5ab32519140341eebad1e15228deb3e2",
      "6b7700e80d854914ad4f75c34e338d3e",
      "77b06e361d74438fad7a17c8f34c0aa1",
      "c2ba33ed9a314536bffb427470ee1957",
      "b15dd251352142d39fb0c1a46cf9b388",
      "2ee881decbf04d1cbc933c20ab8bc714",
      "e879cb6793ff45e4886866587f71db62",
      "08f0ea7c403040968f079e0e694286b7",
      "04aac2c8d09544f88e1b50f7ac048ca7",
      "22f0476c8b2f48a8868bd2216ed4d7cf",
      "abc2dd3740504f31bcc05d4ca007e658",
      "d0ab580d14614370b83ce50e456b1e75"
     ]
    },
    "id": "O3dmAEtuQ9l5",
    "outputId": "b4634db3-939c-4a67-c6f8-8975af1ed448"
   },
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "test_preds_lstm_noquant, test_loss_lstm_noquant, test_accuracy_lstm_noquant = evaluate_model(model_lstm, test_loader, device, quantize=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With Quantization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "test_preds_lstm_quant, test_loss_lstm_quant, test_accuracy_lstm_quant = evaluate_model(model_lstm, test_loader, device, quantize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Percent Difference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check results\n",
    "percent_diff_lstm = mean_percent_diff(test_preds_lstm_quant, test_preds_lstm_noquant)\n",
    "\n",
    "print(f\"Mean Percent Difference between outputs (non-quantized vs quantized) LSTM: {percent_diff_lstm:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bliBob-oRT-A"
   },
   "source": [
    "### GRU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_type = 'gru'\n",
    "\n",
    "# Training\n",
    "model_gru = train_or_load_model(configs, train_loader, val_loader, rnn_type, device)\n",
    "\n",
    "# Export model parameters to JSON file\n",
    "export_model_parameters(model_gru, f'models/SC2010_quantized_{rnn_type}_parameters.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Without Quantization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yItI-2tcPEZf",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "test_preds_gru_noquant, test_loss_gru_noquant, test_accuracy_gru_noquant = evaluate_model(model_gru, test_loader, device, quantize=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With Quantization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "test_preds_gru_quant, test_loss_gru_quant, test_accuracy_gru_quant = evaluate_model(model_gru_quant, test_loader, device, quantize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Percent Difference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check results\n",
    "percent_diff_gru = mean_percent_diff(test_preds_gru_quant, test_preds_gru_noquant)\n",
    "print(f\"Mean Percent Difference between outputs (non-quantized vs quantized) GRU: {percent_diff_gru:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "01289697a46a4749808002f2a6eaaf73": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b1f95063a92b48e0b5ca86e7a6716236",
      "placeholder": "",
      "style": "IPY_MODEL_abf1a93ee34843578018f72eeb64a9ea",
      "value": "0%"
     }
    },
    "04aac2c8d09544f88e1b50f7ac048ca7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "08f0ea7c403040968f079e0e694286b7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "18429f5771a24ae1a72150c16e7f97d3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "22f0476c8b2f48a8868bd2216ed4d7cf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2ee881decbf04d1cbc933c20ab8bc714": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "497e7dd3069a4b5dbc883e4695332963": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5ab32519140341eebad1e15228deb3e2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6b7700e80d854914ad4f75c34e338d3e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_77b06e361d74438fad7a17c8f34c0aa1",
       "IPY_MODEL_c2ba33ed9a314536bffb427470ee1957",
       "IPY_MODEL_b15dd251352142d39fb0c1a46cf9b388"
      ],
      "layout": "IPY_MODEL_2ee881decbf04d1cbc933c20ab8bc714"
     }
    },
    "77b06e361d74438fad7a17c8f34c0aa1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e879cb6793ff45e4886866587f71db62",
      "placeholder": "",
      "style": "IPY_MODEL_08f0ea7c403040968f079e0e694286b7",
      "value": ""
     }
    },
    "95eca35a46a14aa4abf7c91b1ccee065": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_01289697a46a4749808002f2a6eaaf73",
       "IPY_MODEL_9ff6b3cf75b746f5a11dc7a7eadc2009",
       "IPY_MODEL_e86b3864d880446081ae53689493f24e"
      ],
      "layout": "IPY_MODEL_c275aca6f2c84125923cbd7246786078"
     }
    },
    "9ff6b3cf75b746f5a11dc7a7eadc2009": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_18429f5771a24ae1a72150c16e7f97d3",
      "max": 50,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a583468ab883499e9d8cc9dadac9c597",
      "value": 0
     }
    },
    "a583468ab883499e9d8cc9dadac9c597": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "abc2dd3740504f31bcc05d4ca007e658": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "abf1a93ee34843578018f72eeb64a9ea": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b15dd251352142d39fb0c1a46cf9b388": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_abc2dd3740504f31bcc05d4ca007e658",
      "placeholder": "",
      "style": "IPY_MODEL_d0ab580d14614370b83ce50e456b1e75",
      "value": "0/?[00:00&lt;?,?it/s]"
     }
    },
    "b1f95063a92b48e0b5ca86e7a6716236": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c275aca6f2c84125923cbd7246786078": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c2ba33ed9a314536bffb427470ee1957": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_04aac2c8d09544f88e1b50f7ac048ca7",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_22f0476c8b2f48a8868bd2216ed4d7cf",
      "value": 0
     }
    },
    "d0ab580d14614370b83ce50e456b1e75": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e86b3864d880446081ae53689493f24e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_497e7dd3069a4b5dbc883e4695332963",
      "placeholder": "",
      "style": "IPY_MODEL_5ab32519140341eebad1e15228deb3e2",
      "value": "0/50[00:00&lt;?,?it/s]"
     }
    },
    "e879cb6793ff45e4886866587f71db62": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
